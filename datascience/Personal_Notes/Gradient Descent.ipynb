{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "\n",
    "Gradient descent is a first-order iterative optimization algorithm for finding the minimum of a function. To find a local minimum of a function using gradient descent, one takes steps proportional to the negative of the gradient (or of the approximate gradient) of the function at the current point. If instead one takes steps proportional to the positive of the gradient, one approaches a local maximum of that function; the procedure is then known as gradient ascent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\\begin{align*} \\text{repeat until convergence: } \\lbrace & \\newline \\theta_0 := & \\theta_0 - \\alpha \\frac{1}{m} \\sum\\limits_{i=1}^{m}(h_\\theta(x_{i}) - y_{i}) \\newline \\theta_1 := & \\theta_1 - \\alpha \\frac{1}{m} \\sum\\limits_{i=1}^{m}\\left((h_\\theta(x_{i}) - y_{i}) x_{i}\\right) \\newline \\rbrace& \\end{align*}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "\n",
    "def generateSample(N, variance=100):\n",
    "    X = np.matrix(range(N)).T + 1\n",
    "    Y = np.matrix([random.random() * variance + i * 10 + 900 for i in range(len(X))]).T\n",
    "    # T\tReturns the transpose of the matrix.\n",
    "    return X, Y\n",
    "\n",
    "def fitModel_gradient(x, y):\n",
    "    N = len(x)\n",
    "    # we initilize the weight in here \n",
    "    w = np.zeros((x.shape[1], 1))\n",
    "    # aka. learning rate\n",
    "    eta = 0.001\n",
    "\n",
    "    maxIteration = 10000\n",
    "    for i in range(maxIteration):\n",
    "        # x * w in here our guess. \n",
    "        # y is the real value\n",
    "        error = x * w - y\n",
    "        # gradient  \n",
    "        gradient = x.T * error / N\n",
    "        # w = weight. \n",
    "        w = w - eta * gradient\n",
    "        if(i % 1000 == 0):\n",
    "            input()\n",
    "            plotModel(x, y, w)\n",
    "    return w\n",
    "\n",
    "\n",
    "def plotModel(x, y, w):\n",
    "    plt.plot(x[:,1], y, \"x\")\n",
    "    plt.plot(x[:,1], x * w, \"r-\")\n",
    "    plt.show()\n",
    "    \n",
    "def test(N, variance, modelFunction):\n",
    "    # generate sample data\n",
    "    X, Y = generateSample(N, variance)\n",
    "    # X is numeric numbers 1,2,3,4\n",
    "    # Y is random value\n",
    "    # lets convert it to matrix.\n",
    "    # before [1] ....\n",
    "    X = np.hstack([np.matrix(np.ones(len(X))).T, X])\n",
    "    # after [[  1.   1.] ...\n",
    "    w = modelFunction(X, Y)\n",
    "    plotModel(X, Y, w)\n",
    "    \n",
    "    \n",
    "test(50, 600, fitModel_gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
